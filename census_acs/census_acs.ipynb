{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census ACS\n",
    "\n",
    "Retrieves data from the Census Bureau's American Community Survey 5-year series API for zctas, pumas, and tracts. A specific list of census variables is passed into the script, which are retrieved from the four ACS profile tables. Variables must be retrieved in chunks because only 50 can be passed to the API at a time, and each url varies by geography and retreives them in different combinations. After some processing output is written to a SQLite database. An option to create a metadata table appears at the bottom, but should only be run once for a given extract (acs1 and acs2) and not for each individual geography.\n",
    "\n",
    "https://www.census.gov/data/developers/data-sets/acs-5year.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, json, sqlite3, random, pandas as pd, numpy as np\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyfile='census_key.txt'\n",
    "\n",
    "#API variables - UPDATE THE YEAR AND GEO\n",
    "year='2018'\n",
    "geo='public use microdata area' # 'zip code tabulation area' or 'public use microdata area' or 'tract'\n",
    "state='36'\n",
    "dsource='acs'\n",
    "dsource2='acs5'\n",
    "dname='profile'\n",
    "\n",
    "#Variables to read in from spreadsheet - UPDATE WORKSHEET\n",
    "worksheet='acs2' # 'acs1' or 'acs2'\n",
    "geoexcelsheet={'zip code tabulation area':'zctas', 'public use microdata area':'pumas', 'tract':'tracts'}\n",
    "geotype=geoexcelsheet.get(geo)\n",
    "\n",
    "#SQL output\n",
    "tabname='{}_{}{}'.format(geotype,year,worksheet)\n",
    "dbname=os.path.join('outputs','testdb.sqlite')\n",
    "\n",
    "#Dump files for api data storage\n",
    "jsonpath=os.path.join('outputs', tabname+'_retrieved_data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Lists\n",
    "Get full list of variables from the API, read in our retrieval list, and compare the varianle IDs and names to make sure nothing is missing and that nothing has changed since the last iteration. *Don't move on to the next block until both lists match.* Lastly, read in list of geographies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadict={}\n",
    "dps=['DP02','DP03','DP04','DP05']\n",
    "for p in dps:\n",
    "    vars_url = f'https://api.census.gov/data/{year}/{dsource}/{dsource2}/{dname}/groups/{p}.json'\n",
    "    response=requests.get(vars_url)\n",
    "    var_data=response.json()\n",
    "    datadict.update(var_data['variables'])\n",
    "random.sample(datadict.items(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexcel = pd.read_excel(os.path.join('inputs','acs_variables.xlsx'),sheet_name=worksheet)\n",
    "dfexcel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfvars = pd.DataFrame.from_dict(datadict,columns=['label'],orient='index')\n",
    "dfvars_selected=dfvars.loc[dfvars.index.isin(dfexcel['census_var'])]\n",
    "dfvars_count=len(dfvars_selected)\n",
    "dfexcel_count=len(dfexcel['census_var'])\n",
    "\n",
    "if dfvars_count==dfexcel_count:\n",
    "    print('There are an equal number of variables in both lists:', dfvars_count)\n",
    "else:\n",
    "    print('There is a mismatch in the number of variables; the api has,', dfvars_count, \n",
    "          'while the original list has',dfexcel_count,'. Missing:')\n",
    "    nomatch=dfexcel[~dfexcel['census_var'].isin(dfvars_selected.index)]\n",
    "    print(nomatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch=dfexcel[~dfexcel['census_label'].isin(dfvars_selected['label'])]\n",
    "\n",
    "if len (mismatch) ==0:\n",
    "    print('All labels match')\n",
    "else:\n",
    "    compare=pd.merge(mismatch,dfvars_selected, left_on='census_var', right_on=dfvars_selected.index)\n",
    "    misfile=os.path.join('outputs','{}_mismatch.csv'.format(worksheet))\n",
    "    compare.to_csv(misfile, columns=['db_var', 'census_var', 'census_label', 'label'],sep=',', index=False,\n",
    "    header=['db_var','census_var' ,'oldlabel','newlabel'])\n",
    "    print('* Mismatch file printed to outputs folder * \\n')\n",
    "    print('These labels do not match:')\n",
    "    print(compare[['census_var','census_label','label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geographic indetifiers: zctas to retrieve, pumas to filter by, and counties containing tracts to retrieve\n",
    "excelgeo = pd.read_excel(os.path.join('inputs','acs_variables.xlsx'),sheet_name=geotype, dtype=object)\n",
    "geoids = excelgeo['GEO'].tolist()\n",
    "print('Number of geographic indetifiers:',len(geoids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Data\n",
    "Given the large number of variables in the ACS and limits of the API, variables must be passed to the url in separate blocks or chunks. The first chunk that's captured is written to an empty datalist; the header row and then one row for each geography. Each subsequent chunk is iterated through by row, so each row is appended to the correct row in datalist. In all cases, the last values, identifiers automatically returned with each API call, are not appended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    # For item i in a range that is a length of l,\n",
    "    for i in range(0, len(l), n):\n",
    "        # Create an index range for l of n items:\n",
    "        yield l[i:i+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reqvars=list(chunks(dfvars_selected.index.tolist(),46))\n",
    "reqvars[0].insert(0,'NAME')\n",
    "reqvars[0].insert(0,'GEO_ID')\n",
    "print('Number of chunks:',len(reqvars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(keyfile) as key:\n",
    "    api_key=key.read().strip()\n",
    "\n",
    "base_url = f'https://api.census.gov/data/{year}/{dsource}/{dsource2}/{dname}'\n",
    "base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for retrieving data; running this block loads it into memory\n",
    "#Different geographies have different urls, \n",
    "#and a different number of identifiers tacked on to the end of each request\n",
    "\n",
    "def getdata():\n",
    "    dlist=[]\n",
    "    for i, v in enumerate(reqvars):\n",
    "        batchcols=','.join(v)\n",
    "        if geotype=='zctas':\n",
    "            data_url = f'{base_url}?get={batchcols}&for={geo}:{g}&key={api_key}'\n",
    "            dropvar=-1\n",
    "        elif geotype=='pumas':\n",
    "            data_url = f'{base_url}?get={batchcols}&for={geo}:*&in=state:{state}&key={api_key}'\n",
    "            dropvar=-2\n",
    "        elif geotype=='tracts':\n",
    "            data_url = f'{base_url}?get={batchcols}&for={geo}:*&in=state:{state}&in=county:{county}&key={api_key}'\n",
    "            dropvar=-3\n",
    "        else:\n",
    "            print('Appropriate geography not specified in variables block')\n",
    "            break  \n",
    "        response=requests.get(data_url)\n",
    "        if response.status_code==200:\n",
    "            clear_output(wait=True)\n",
    "            data=response.json()\n",
    "            for i2, v2 in enumerate(data):\n",
    "                if i == 0:\n",
    "                    dlist.append(v2[:dropvar])\n",
    "                else:\n",
    "                    for item in v2[:dropvar]:\n",
    "                        dlist[i2].append(item)\n",
    "        else:\n",
    "            print('***Problem with retrieval***, response code',response.status_code)\n",
    "    return dlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***THIS BLOCK IS A REQUESTS BLOCK!***\n",
    "*NOTE: ZCTA retrieval takes a long time - 15 mins for 215 ZCTAs*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If this block was run successfully for a given table and geography don't rerun - next block pulls from saved json\n",
    "datalist=[]\n",
    "if geotype=='zctas':\n",
    "    for g in geoids:\n",
    "        georecord=getdata()\n",
    "        print('Retrieved data for',g)\n",
    "        if len(datalist)==0:\n",
    "            datalist.append(georecord[0])\n",
    "            datalist.append(georecord[1])\n",
    "        else:\n",
    "            datalist.append(georecord[1])\n",
    "elif geotype=='pumas':\n",
    "    datalist=getdata()\n",
    "elif geotype=='tracts':\n",
    "    for county in geoids:\n",
    "        georecord=getdata()\n",
    "        print('Retrieved data for',county)\n",
    "        if len(datalist)==0:\n",
    "            for tract in georecord:\n",
    "                datalist.append(tract)\n",
    "        else:\n",
    "            for tract in georecord[1:]:\n",
    "                datalist.append(tract)\n",
    "    \n",
    "dlrows=len(datalist)\n",
    "dlitems=sum(len(x) for x in datalist)\n",
    "dlbyrow=dlitems / dlrows\n",
    "print('Retrieved', dlrows, 'records and', dlitems,'data points with', dlbyrow, 'points for each record...')\n",
    "        \n",
    "with open(jsonpath, 'w') as f:\n",
    "    json.dump(datalist, f)\n",
    "print('Done - Data dumped to json file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data\n",
    "Replace footnotes with nulls, create a new GEOID2 column, replace census variable names with database variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(jsonpath, 'r') as f:\n",
    "    jsondata=json.load(f)\n",
    "alldata = pd.DataFrame(jsondata[1:],columns=jsondata[0],dtype=object).rename(columns={\n",
    "    'GEO_ID':'GEOID','NAME':'GEOLABEL'}).set_index('GEOID')\n",
    "alldata.info()\n",
    "# Index and column entries should be 1 row and 1 column less than previous count (excludes header row and index column) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a lousy solution, come up with something better in the future\n",
    "footnotes=['-999999999','-999999999.0', '-999999999.00',\n",
    "           '-888888888','-888888888.0', '-888888888.00',\n",
    "           '-666666666','-666666666.0', '-666666666.00',\n",
    "           '-555555555','-555555555.0', '-555555555.00',\n",
    "           '-333333333','-333333333.0', '-333333333.00',\n",
    "           '-222222222','-222222222.0', '-222222222.00']\n",
    "alldata.replace(footnotes,np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxgeoid2={'zctas':-5, 'pumas':-7,'tracts':-11}\n",
    "alldata.insert(loc=0, column='GEOID2',value=alldata.index.str[idxgeoid2.get(geotype):])\n",
    "alldata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For PUMAS filter all the geotype for the state by local areas\n",
    "if geotype == 'pumas':\n",
    "    acsdata=alldata.loc[alldata.GEOID2.isin(geoids)].copy().astype(object).sort_index()\n",
    "else:\n",
    "    acsdata=alldata.copy().astype(object).sort_index()\n",
    "acsdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary of column names from the census and the nyc geodatabase\n",
    "cv_to_db=dict(zip(dfexcel.census_var, dfexcel.db_var))\n",
    "random.sample(cv_to_db.items(), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename the census variables to nyc geodatabase variables\n",
    "acsdata.rename(columns=cv_to_db,inplace=True)\n",
    "acsdata.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to Database\n",
    "Update list of variables and data types, build create table string, create datatable in temporary database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexcel.replace({'dtype': {'int': 'INTEGER', 'float': 'REAL'}},inplace=True)\n",
    "dfexcel.census_label.replace({'!!': ' - '},inplace=True, regex=True)\n",
    "dfexcel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vardict=dfexcel.set_index('db_var').T.to_dict('list')\n",
    "random.sample(vardict.items(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(dbname) \n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('DROP TABLE IF EXISTS {}'.format(tabname))\n",
    "dbstring=\"\"\"\n",
    "CREATE TABLE {} (\n",
    "GEOID TEXT,\n",
    "GEOID2 TEXT NOT NULL PRIMARY KEY,\n",
    "GEOLABEL TEXT,\n",
    "\"\"\".format(tabname)\n",
    "\n",
    "for k,v in vardict.items():\n",
    "    dbstring=dbstring+k+' '+v[2]+', \\n'\n",
    "    \n",
    "dbstring=dbstring[:-3]\n",
    "dbstring=dbstring+');'\n",
    "print(dbstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(dbstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acsdata.to_sql(name=tabname, if_exists='append', index=True, con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('SELECT COUNT(*) FROM {};'.format(tabname))\n",
    "rows = cur.fetchone()\n",
    "print(rows[0], 'records written to', tabname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('SELECT * FROM {} LIMIT 1;'.format(tabname))\n",
    "col_names = [cn[0] for cn in cur.description]\n",
    "print(len(col_names), 'columns written to', tabname)\n",
    "#Number should be same as number in df acsdata plus 1, since index not included in df count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Table\n",
    "DO NOT RERUN THIS SECTION FOR MULTIPLE GEOGRAPHIES. In the NYC Geodatabase there is only one metadata table for all of the ACS tables (acs1 and acs2) for all geographies. For whichever geography is processed first, set action variable to 'create' and run this entire series of blocks for the acs1 table. For the acs2 table, set the action variable to 'append' and skip the table creation and identifier insertion blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change table name and specify an action - you're creating the table for the first time with acs1 variables, \n",
    "#or appending the tables with acs2 variables\n",
    "\n",
    "metatab='acslookup2017'\n",
    "action='create' # 'create' or 'append'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(dbname) \n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only run this block when creating initial table\n",
    "if action=='create':\n",
    "    mdstring=\"\"\"\n",
    "    CREATE TABLE {} (\n",
    "    tabnum TEXT,\n",
    "    est_id TEXT,\n",
    "    est_value TEXT);\n",
    "    \"\"\".format(metatab)\n",
    "    cur.execute(mdstring)\n",
    "else:\n",
    "    print('Block not executed because \"create\" not selected as an action in earlier block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only run this block when creating initial table\n",
    "if action=='create':\n",
    "    exstring=\"\"\"\n",
    "        INSERT INTO {} VALUES('both','NOTE','Each variable has 4 values that are identified by a particular suffix: E for estimate, M for margin of error for the estimate, PC for percent total, and PM for margin of error for the percent total');\n",
    "        INSERT INTO {} VALUES('both','GEOID','Id');\n",
    "        INSERT INTO {} VALUES('both','GEOID2','Id2');\n",
    "        INSERT INTO {} VALUES('both','GEOLABEL','Geography');\n",
    "        \"\"\".format(metatab,metatab,metatab,metatab)\n",
    "    cur.executescript(exstring)\n",
    "    con.commit()\n",
    "else:\n",
    "    print('Block not executed because \"create\" not selected as an action in earlier block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run when creating table or when appending records\n",
    "#Keys and values - db ids and labels - are simplified and truncated to 1 entry for each 4-column group (E,M,PC,PM)\n",
    "if action in ('create','append'):\n",
    "    for mk, mv in vardict.items():\n",
    "        if mk.endswith('_E'):\n",
    "            cur.execute(\"INSERT INTO {} values(?,?,?)\".format(metatab),(worksheet,mk[:-2],mv[1][11:]))\n",
    "    con.commit()\n",
    "else:\n",
    "    print('Block not executed because action not specified in earlier block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('SELECT COUNT(*) FROM {};'.format(metatab))\n",
    "rows = cur.fetchone()\n",
    "print(rows[0], 'records in', metatab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action=''\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
