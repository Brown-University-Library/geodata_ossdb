{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Census ACS\n",
    "Retrieves data from the Census Bureau's American Community Survey 5-year series API for a given area. A specific list of census variables is passed into the script, which are retrieved from the four ACS profile tables. After some processing output is written to a SQLite database. Option to create a metadata table appears at the bottom, but should only be run in limited instances.\n",
    "\n",
    "https://www.census.gov/data/developers/data-sets/acs-5year.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, json, pandas as pd, numpy as np, sqlite3\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyfile='census_key.txt'\n",
    "\n",
    "#API variables - UPDATE THE YEAR AND GEO\n",
    "year='2017'\n",
    "dsource='acs'\n",
    "dsource2='acs5'\n",
    "dname='profile'\n",
    "state='36'\n",
    "geo='zip code tabulation area'\n",
    "#geo='public use microdata area'\n",
    "\n",
    "#Variables to read in - UPDATE THE SHEET\n",
    "worksheet='acs1'\n",
    "#worksheet='acs2'\n",
    "geogs='zctas'\n",
    "#geogs='pumas'\n",
    "\n",
    "#SQL output - UPDATE TABLE NAME\n",
    "tabname='pumas_2017acs1'\n",
    "#tabname='pumas_2017acs2'\n",
    "dbname=os.path.join('outputs','testdb.sqlite')\n",
    "\n",
    "#Dump files for api data storage\n",
    "jsonpath=os.path.join('outputs', tabname+'_retrieved_data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable List\n",
    "Get full list of variables from the API, read in our retrieval list, and compare the ID codes and names to make sure nothing is missing and that nothing has changed since the last iteration. Don't move on to the next block until both lists match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('DP02_0019EA',\n",
       " {'label': 'Annotation of Estimate!!RELATIONSHIP!!Population in households!!Spouse',\n",
       "  'predicateType': 'string',\n",
       "  'group': 'DP02',\n",
       "  'limit': 0,\n",
       "  'predicateOnly': True})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadict={}\n",
    "dps=['DP02','DP03','DP04','DP05']\n",
    "for p in dps:\n",
    "    vars_url = f'https://api.census.gov/data/{year}/{dsource}/{dsource2}/{dname}/groups/{p}.json'\n",
    "    response=requests.get(vars_url)\n",
    "    var_data=response.json()\n",
    "    datadict.update(var_data['variables'])\n",
    "next(iter(datadict.items() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_var</th>\n",
       "      <th>census_var</th>\n",
       "      <th>census_label</th>\n",
       "      <th>dtype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HSHD01_E</td>\n",
       "      <td>DP02_0001E</td>\n",
       "      <td>Estimate!!HOUSEHOLDS BY TYPE!!Total households</td>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HSHD01_M</td>\n",
       "      <td>DP02_0001M</td>\n",
       "      <td>Margin of Error!!HOUSEHOLDS BY TYPE!!Total hou...</td>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HSHD01_PC</td>\n",
       "      <td>DP02_0001PE</td>\n",
       "      <td>Percent Estimate!!HOUSEHOLDS BY TYPE!!Total ho...</td>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HSHD01_PM</td>\n",
       "      <td>DP02_0001PM</td>\n",
       "      <td>Percent Margin of Error!!HOUSEHOLDS BY TYPE!!T...</td>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HSHD02_E</td>\n",
       "      <td>DP02_0002E</td>\n",
       "      <td>Estimate!!HOUSEHOLDS BY TYPE!!Total households...</td>\n",
       "      <td>int</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      db_var   census_var                                       census_label  \\\n",
       "0   HSHD01_E   DP02_0001E     Estimate!!HOUSEHOLDS BY TYPE!!Total households   \n",
       "1   HSHD01_M   DP02_0001M  Margin of Error!!HOUSEHOLDS BY TYPE!!Total hou...   \n",
       "2  HSHD01_PC  DP02_0001PE  Percent Estimate!!HOUSEHOLDS BY TYPE!!Total ho...   \n",
       "3  HSHD01_PM  DP02_0001PM  Percent Margin of Error!!HOUSEHOLDS BY TYPE!!T...   \n",
       "4   HSHD02_E   DP02_0002E  Estimate!!HOUSEHOLDS BY TYPE!!Total households...   \n",
       "\n",
       "  dtype  \n",
       "0   int  \n",
       "1   int  \n",
       "2   int  \n",
       "3   int  \n",
       "4   int  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfexcel = pd.read_excel(os.path.join('inputs','acs_variables.xlsx'),sheet_name=worksheet)\n",
    "dfexcel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are an equal number of variables in both lists: 248\n"
     ]
    }
   ],
   "source": [
    "dfvars = pd.DataFrame.from_dict(datadict,columns=['label'],orient='index')\n",
    "dfvars_selected=dfvars.loc[dfvars.index.isin(dfexcel['census_var'])]\n",
    "dfvars_count=len(dfvars_selected)\n",
    "dfexcel_count=len(dfexcel['census_var'])\n",
    "\n",
    "if dfvars_count==dfexcel_count:\n",
    "    print('There are an equal number of variables in both lists:', dfvars_count)\n",
    "else:\n",
    "    print('There is a mismatch in the number of variables; the api has retrieved', \n",
    "          dfvars_count, 'while the original list has',dfexcel_count,'. Missing:')\n",
    "    nomatch=dfexcel[~dfexcel['census_var'].isin(dfvars_selected.index)]\n",
    "    print(nomatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All labels match\n"
     ]
    }
   ],
   "source": [
    "mismatch=dfexcel[~dfexcel['census_label'].isin(dfvars_selected['label'])]\n",
    "\n",
    "if len (mismatch) ==0:\n",
    "    print('All labels match')\n",
    "else:\n",
    "    test=pd.merge(mismatch,dfvars_selected, left_on='census_var', right_on=dfvars_selected.index)\n",
    "    print('These labels do not match:')\n",
    "    print(test[['census_var','census_label','label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excelgeo = pd.read_excel(os.path.join('inputs','acs_variables.xlsx'),sheet_name=geogs, dtype=object)\n",
    "geoids = excelgeo['GEO'].tolist()\n",
    "len(geoids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Data\n",
    "Given the large number of variables in the ACS and limits of the API, variables must be passed to the url in separate blocks or chunks. The first chunk that's captured is written to an empty datalist; the header row and then one row for each geography. Each subsequent chunk is iterated through by row, so each row is appended to the correct row in datalist. In both cases, the last two values (identifiers automatically returned with each API call) are not appended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(l, n):\n",
    "    # For item i in a range that is a length of l,\n",
    "    for i in range(0, len(l), n):\n",
    "        # Create an index range for l of n items:\n",
    "        yield l[i:i+n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks including header row: 6\n"
     ]
    }
   ],
   "source": [
    "reqvars=list(chunks(dfvars_selected.index.tolist(),46))\n",
    "reqvars[0].insert(0,'NAME')\n",
    "reqvars[0].insert(0,'GEO_ID')\n",
    "print('Number of chunks including header row:',len(reqvars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://api.census.gov/data/2017/acs/acs5/profile'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(keyfile) as key:\n",
    "    api_key=key.read().strip()\n",
    "\n",
    "base_url = f'https://api.census.gov/data/{year}/{dsource}/{dsource2}/{dname}'\n",
    "base_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ***THIS BLOCK IS A REQUESTS BLOCK!***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved data for 10004\n",
      "Done - retrieved 5 records and 1250 data points with 250.0 data points for each record\n",
      "Data dumped to json file\n"
     ]
    }
   ],
   "source": [
    "#TESTING\n",
    "\n",
    "def getdata():\n",
    "    dlist=[]\n",
    "    for i, v in enumerate(reqvars):\n",
    "        batchcols=','.join(v)\n",
    "        if geogs=='pumas':\n",
    "            data_url = f'{base_url}?get={batchcols}&for={geo}:{g}&in=state:{state}&key={api_key}'\n",
    "            dropvar=-2\n",
    "        elif geogs=='zctas':\n",
    "            data_url = f'{base_url}?get={batchcols}&for={geo}:{g}&key={api_key}'\n",
    "            dropvar=-1     \n",
    "        response=requests.get(data_url)\n",
    "        if response.status_code==200:\n",
    "            clear_output(wait=True)\n",
    "            data=response.json()\n",
    "            for i2, v2 in enumerate(data):\n",
    "                if i == 0:\n",
    "                    dlist.append(v2[:dropvar])\n",
    "                else:\n",
    "                    for item in v2[:dropvar]:\n",
    "                        dlist[i2].append(item)\n",
    "        else:\n",
    "            print('***Problem with retrieval***, response code',response.status_code)\n",
    "    return dlist\n",
    "\n",
    "datalist=[]\n",
    "\n",
    "if geogs=='zctas':\n",
    "    for g in geoids[0:4]:\n",
    "        georecord=getdata()\n",
    "        print('Retrieved data for',g)\n",
    "        if len(datalist)==0:\n",
    "            datalist.append(georecord[0])\n",
    "            datalist.append(georecord[1])\n",
    "        else:\n",
    "            datalist.append(georecord[1])\n",
    "elif geogs=='pumas':\n",
    "    georecord=getdata()\n",
    "    datalist.append(georecord)\n",
    "    \n",
    "dlrows=len(datalist)\n",
    "dlitems=sum(len(x) for x in datalist)\n",
    "dlbyrow=dlitems / dlrows\n",
    "\n",
    "print('Done - retrieved', dlrows, 'records and', dlitems,'data points with', dlbyrow, 'data points for each record')\n",
    "        \n",
    "with open(jsonpath, 'w') as f:\n",
    "    json.dump(datalist, f)\n",
    "print('Data dumped to json file')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XXX\n",
    "#If this block is successful and there are subsequent problems, do not rerun it - start from the following block.\n",
    "\n",
    "def getdata():\n",
    "    dlist=[]\n",
    "    for g in geoids[0:4]:\n",
    "        georecord=[]\n",
    "        for i, v in enumerate(reqvars):\n",
    "            batchcols=','.join(v)\n",
    "            if geogs=='pumas':\n",
    "                data_url = f'{base_url}?get={batchcols}&for={geo}:{g}&in=state:{state}&key={api_key}'\n",
    "                dropvar=-2\n",
    "            elif geogs=='zctas':\n",
    "                data_url = f'{base_url}?get={batchcols}&for={geo}:{g}&key={api_key}'\n",
    "                dropvar=-1     \n",
    "            response=requests.get(data_url)\n",
    "            if response.status_code==200:\n",
    "                clear_output(wait=True)\n",
    "                data=response.json()\n",
    "                for i2, v2 in enumerate(data):\n",
    "                    if i == 0:\n",
    "                        georecord.append(v2[:dropvar])\n",
    "                    else:\n",
    "                        for item in v2[:dropvar]:\n",
    "                            georecord[i2].append(item)\n",
    "            else:\n",
    "                print('***Problem with retrieval***, response code',response.status_code)\n",
    "        if len(dlist)==0:\n",
    "            dlist.append(georecord[0])\n",
    "            dlist.append(georecord[1])\n",
    "        else:\n",
    "            dlist.append(georecord[1])\n",
    "        print('Retrieved all variables for', g)\n",
    "    return dlist\n",
    "\n",
    "datalist=getdata()\n",
    "\n",
    "dlrows=len(datalist)\n",
    "dlitems=sum(len(x) for x in datalist)\n",
    "dlbyrow=dlitems / dlrows\n",
    "\n",
    "print('Done - retrieved', dlrows, 'records and', dlitems,'data points with', dlbyrow, 'data points for each record')\n",
    "        \n",
    "with open(jsonpath, 'w') as f:\n",
    "    json.dump(datalist, f)\n",
    "print('Data dumped to json file')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If this block is successful and there are subsequent problems, do not rerun it - start from the following block.\n",
    "# datalist=[]\n",
    "# c=0\n",
    "\n",
    "# for i, v in enumerate(reqvars):\n",
    "#     batchcols=','.join(v)\n",
    "#     data_url = f'{base_url}?get={batchcols}&for={geo}:*&in=state:{state}&key={api_key}'\n",
    "#     response=requests.get(data_url)\n",
    "#     if response.status_code==200:\n",
    "#         clear_output(wait=True)\n",
    "#         data=response.json()\n",
    "#         for i2, v2 in enumerate(data):\n",
    "#             if i == 0:\n",
    "#                 datalist.append(v2[:-2])\n",
    "#             else:\n",
    "#                 for item in v2[:-2]:\n",
    "#                     datalist[i2].append(item)\n",
    "#         c=c+1\n",
    "#         print(c,'chunks of data written so far')\n",
    "#     else:\n",
    "#         print('***Problem with retrieval***, response code',response.status_code)\n",
    "        \n",
    "# dlrows=len(datalist)\n",
    "# dlitems=sum(len(x) for x in datalist)\n",
    "# dlbyrow=dlitems / dlrows\n",
    "\n",
    "# print('Done - retrieved', dlrows, 'records and', dlitems,'data points with', dlbyrow, 'data points for each record')\n",
    "        \n",
    "# with open(jsonpath, 'w') as f:\n",
    "#     json.dump(datalist, f)\n",
    "# print('Data dumped to json file')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Data\n",
    "Create a new GEOID2 column, replace footnotes with nulls, replace census variable names with database variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(jsonpath, 'r') as f:\n",
    "    jsondata=json.load(f)\n",
    "alldata = pd.DataFrame(jsondata[1:],columns=jsondata[0]).rename(columns={'GEO_ID':'GEOID','NAME':'GEOLABEL'}).set_index('GEOID')\n",
    "alldata.shape\n",
    "# Shape should be 1 row and 1 column less than previous count (excludes header row and index column) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alldata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelgeo = pd.read_excel(os.path.join('inputs','acs_variables.xlsx'),sheet_name=geogs)\n",
    "geoids = excelgeo['GEOID'].tolist()\n",
    "len(geoids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acsdata=alldata.loc[alldata.index.isin(geoids)].copy().sort_index()\n",
    "acsdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acsdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acsdata.insert(loc=0, column='GEOID2',value=acsdata.index.str[-7:])\n",
    "acsdata.replace('-888888888',np.nan,inplace=True)\n",
    "acsdata.replace('-888888888.0',np.nan,inplace=True)\n",
    "acsdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_to_db=dict(zip(dfexcel.census_var, dfexcel.db_var))\n",
    "cv_to_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acsdata.rename(columns=cv_to_db,inplace=True)\n",
    "acsdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to Database\n",
    "Update list of variables and data types, build create table string, create datatable in temporary database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfexcel.replace({'dtype': {'int': 'INTEGER', 'float': 'REAL'}},inplace=True)\n",
    "dfexcel.census_label.replace({'!!': ' - '},inplace=True, regex=True)\n",
    "dfexcel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vardict=dfexcel.set_index('db_var').T.to_dict('list')\n",
    "vardict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('test.sqlite') \n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('DROP TABLE IF EXISTS {}'.format(tabname))\n",
    "dbstring=\"\"\"\n",
    "CREATE TABLE {} (\n",
    "GEOID TEXT,\n",
    "GEOID2 TEXT NOT NULL PRIMARY KEY,\n",
    "GEOLABEL TEXT,\n",
    "\"\"\".format(tabname)\n",
    "\n",
    "for k,v in vardict.items():\n",
    "    dbstring=dbstring+k+' '+v[2]+', \\n'\n",
    "    \n",
    "dbstring=dbstring[:-3]\n",
    "dbstring=dbstring+');'\n",
    "print(dbstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(dbstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acsdata.to_sql(name=tabname, if_exists='append', index=True, con=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('SELECT COUNT(*) FROM {};'.format(tabname))\n",
    "rows = cur.fetchone()\n",
    "print(rows[0], 'records written to', tabname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata Table\n",
    "DO NOT RERUN THIS SECTION FOR MULTIPLE GEOGRAPHIES. In the NYC Geodatabase there is only one metadata table for all of the ACS tables (acs1 and acs2) for all geographies. For whichever geography is processed first, set action variable to 'create' and run this entire series of blocks for the acs1 table. For the acs2 table, set the action variable to 'append' and skip the table creation and identifier insertion blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change table name and specify an action - you're creating the table for the first time with acs1 variables, \n",
    "#or appending the tables with acs2 variables\n",
    "\n",
    "metatab='acslookup2017'\n",
    "action='create' # modify to 'create' or 'append'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect('test.sqlite') \n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only run this block when creating initial table\n",
    "if action=='create':\n",
    "    mdstring=\"\"\"\n",
    "    CREATE TABLE {} (\n",
    "    tabnum TEXT,\n",
    "    est_id TEXT,\n",
    "    est_value TEXT);\n",
    "    \"\"\".format(metatab)\n",
    "    cur.execute(mdstring)\n",
    "else:\n",
    "    print('Block not executed because \"create\" not selected as an action in earlier block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only run this block when creating initial table\n",
    "if action=='create':\n",
    "    exstring=\"\"\"\n",
    "        INSERT INTO {} VALUES('both','NOTE','Each variable has 4 values that are identified by a particular suffix: E for estimate, M for margin of error for the estimate, PC for percent total, and PM for margin of error for the percent total');\n",
    "        INSERT INTO {} VALUES('both','GEOID','Id');\n",
    "        INSERT INTO {} VALUES('both','GEOID2','Id2');\n",
    "        INSERT INTO {} VALUES('both','GEOLABEL','Geography');\n",
    "        \"\"\".format(metatab,metatab,metatab,metatab)\n",
    "    cur.executescript(exstring)\n",
    "    con.commit()\n",
    "else:\n",
    "    print('Block not executed because \"create\" not selected as an action in earlier block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run when creating table or when appending records\n",
    "if action in ('create','append'):\n",
    "    for mk, mv in vardict.items():\n",
    "        cur.execute(\"INSERT INTO {} values(?,?,?)\".format(metatab),(worksheet,mk,mv[1]))\n",
    "    con.commit()\n",
    "else:\n",
    "    print('Block not executed because action not specified in earlier block')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute('SELECT COUNT(*) FROM {};'.format(metatab))\n",
    "rows = cur.fetchone()\n",
    "print(rows[0], 'records in', metatab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action=''\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
